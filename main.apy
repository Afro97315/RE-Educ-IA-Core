# fichier : main.py

from fastapi import FastAPI, HTTPException, Query
from pydantic import BaseModel
from typing import List, Dict, Optional
import re
import logging

# === Configuration de base ===
app = FastAPI(
    title="üõ°Ô∏è RE-Educ'-IA ‚Äî D√©tecteur de Biais & Inclusion",
    description="""
    API pour d√©tecter, analyser et corriger les biais racistes, coloniaux, sexistes et discriminants 
    dans les textes, prompts IA et documents institutionnels.
    
    üéØ Objectif : √âradiquer les r√©cits non inclusifs et promouvoir des algorithmes justes.
    """,
    version="2.0",
    docs_url="/",
    redoc_url="/docs"
)

# === Journalisation pour audit ===
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("RE-Educ-IA")

# === BASES DE CONNAISSANCE ===

# 1. Cat√©gories de biais avec mots-cl√©s, explications et reformulations
BIAS_DATABASE = {
    "racisme": {
        "keywords": [
            "sang impur", "inf√©rieur", "primitif", "tribal", "barbare", "race sup√©rieure",
            "n√®gre", "bamboula", "zoulou", "n√©gritude"  # certains utilis√©s historiquement de fa√ßon p√©jorative
        ],
        "explanation": "Utilisation de termes racisants ou hi√©rarchisation raciale des peuples.",
        "inclusive_rewrite": "Toutes les personnes sont √©gales en dignit√© et en droits, ind√©pendamment de leur origine."
    },
    "eurocentrisme": {
        "keywords": [
            "d√©couverte", "mission civilisatrice", "avant la colonisation c'√©tait le chaos",
            "pas de civilisation", "sans histoire", "non d√©velopp√©"
        ],
        "explanation": "Pr√©sente l‚ÄôEurope comme le seul berceau de la civilisation, effa√ßant les empires africains, asiatiques et am√©rindiens.",
        "inclusive_rewrite": "Les soci√©t√©s africaines, comme le Mali, le Kongo ou le Ghana, avaient des √âtats organis√©s, des syst√®mes √©conomiques et des savoirs avanc√©s bien avant la colonisation."
    },
    "sexisme_et_androcentrisme": {
        "keywords": [
            "les rois ont construit", "fondateur", "chef de guerre", "il", "homme", "patriarcat naturel"
        ],
        "explanation": "Invisibilise les femmes et les leaderships f√©minins dans l‚Äôhistoire et la politique.",
        "inclusive_rewrite": "Des femmes comme Yaa Asantewaa, Nehanda, ou la reine Amina de Zaria ont dirig√© des empires et men√© des r√©sistances majeures."
    },
    "invisibilisation_culturelle": {
        "keywords": [
            "sans √©criture", "oralit√© = absence de savoir", "pas de science",
            "aucune technologie", "pas de philosophie"
        ],
        "explanation": "D√©ment les savoirs endog√®nes (m√©decine, astronomie, droit, linguistique) des soci√©t√©s non europ√©ennes.",
        "inclusive_rewrite": "Les soci√©t√©s orales transmettent des savoirs complexes par la parole, la danse, les symboles et les griots."
    },
    "orientalisme_et_exotisation": {
        "keywords": [
            "myst√©rieux", "fanatique", "opprim√©", "voil√© par nature", "terre sacr√©e", "archa√Øque"
        ],
        "explanation": "Reduit les peuples √† des st√©r√©otypes exotiques ou religieux, sans agence ni diversit√©.",
        "inclusive_rewrite": "Les soci√©t√©s du Sud ont des dynamiques internes complexes, des r√©sistances, des innovations et des pens√©es critiques."
    }
}

# 2. Reformulations automatiques (regex pour plus de pr√©cision)
REWRITING_RULES = {
    r'\bd√©couverte\b': "prise de contact avec une r√©gion d√©j√† peupl√©e et organis√©e",
    r'\bmission civilisatrice\b': "justification id√©ologique de l‚Äôexploitation coloniale",
    r'\bprimitif\b': "diff√©rent selon des logiques culturelles propres",
    r'\btribal\b': "organis√© selon des structures communautaires ancestrales",
    r'\bsang impur\b': "concept raciste sans fondement scientifique",
    r'\brace sup√©rieure\b': "hi√©rarchie raciale d√©pass√©e et non valide",
    r'\b(arri√©r√©|non civilis√©)\b': "ayant un mod√®le de d√©veloppement diff√©rent"
}

# 3. Algorithmes ou patterns suspects (pour d√©tecter des biais dans les prompts IA)
ALGORITHMIC_BIAS_PATTERNS = {
    "st√©r√©otype_professionnel": {
        "pattern": r"(femme|noir|arabe).*\b(m√©nage|nettoyage|terroriste|danse|sportif)\b",
        "warning": "Association st√©r√©otyp√©e entre identit√© et m√©tier. Risque de biais dans les suggestions IA."
    },
    "essentialisation": {
        "pattern": r"(toujours|jamais|naturellement|par essence) (violence|docilit√©|paresse|passion)",
        "warning": "Essentialisation dangereuse : attribue des traits fixes √† un groupe."
    },
    "absence_de_contexte": {
        "pattern": r"(pauvret√©|instabilit√©).*sans mention.*colonisation|esclavage|fronti√®res",
        "warning": "Analyse incompl√®te : ignore les causes historiques structurelles."
    }
}

# 4. Perspectives valides
VALID_PERSPECTIVES = [
    "afrocentr√©",
    "d√©colonial",
    "f√©ministe noire",
    "autochtone",
    "intersectionnel",
    "mondialis√© sud-sud"
]

# === MOD√àLES PYDANTIC ===

class ScanRequest(BaseModel):
    text: str
    target_perspective: str = "afrocentr√©"
    include_context: bool = True

class BiasDetected(BaseModel):
    type: str
    keywords_found: List[str]
    explanation: str
    suggested_fix: str

class AlgorithmicWarning(BaseModel):
    type: str
    pattern_match: str
    warning: str

class ScanResponse(BaseModel):
    original_text: str
    detected_biases: List[BiasDetected]
    algorithmic_warnings: List[AlgorithmicWarning]
    suggested_reformulation: str
    added_contextual_notes: List[str] = []
    educational_note: str
    is_inclusive: bool

# === FONCTIONS D'ANALYSE ===

def find_biases(text: str) -> List[Dict]:
    found = []
    text_lower = text.lower()
    matched_words = set()

    for bias_type, data in BIAS_DATABASE.items():
        keywords_found = []
        for kw in data["keywords"]:
            if re.search(r'\b' + re.escape(kw) + r'\b', text_lower, re.IGNORECASE):
                keywords_found.append(kw)
                matched_words.add(kw)

        if keywords_found:
            found.append({
                "type": bias_type,
                "keywords_found": keywords_found,
                "explanation": data["explanation"],
                "suggested_fix": data["inclusive_rewrite"]
            })

    logger.info(f"Mots biais√©s d√©tect√©s : {list(matched_words)}")
    return found

def detect_algorithmic_patterns(text: str) -> List[Dict]:
    warnings = []
    for name, data in ALGORITHMIC_BIAS_PATTERNS.items():
        match = re.search(data["pattern"], text, re.IGNORECASE)
        if match:
            warnings.append({
                "type": name,
                "pattern_match": match.group(0),
                "warning": data["warning"]
            })
    return warnings

def apply_inclusive_rewriting(text: str) -> str:
    result = text
    for pattern, replacement in REWRITING_RULES.items():
        result = re.sub(pattern, replacement, result, flags=re.IGNORECASE)
    return result.strip()

def generate_contextual_notes(text: str) -> List[str]:
    notes = []
    text_lower = text.lower()
    if "afrique" in text_lower and any(kw in text_lower for kw in ["d√©couverte", "pas de", "sans"]):
        notes.append("üìå L‚ÄôAfrique comptait plus de 10 000 √âtats organis√©s avant la colonisation.")
    if "esclavage" in text_lower and "√©conomie" in text_lower:
        notes.append("üìå 25 millions de personnes ont √©t√© d√©plac√©es par l‚Äôesclavage transsaharien et atlantique.")
    return notes

# === ROUTE PRINCIPALE ===

@app.post("/scan", response_model=ScanResponse)
def scanner_texte(request: ScanRequest):
    text = request.text.strip()
    perspective = request.target_perspective.lower()
    include_context = request.include_context

    # Validation
    if not text:
        raise HTTPException(status_code=400, detail="Le champ 'text' est requis.")
    if len(text) > 5000:
        raise HTTPException(status_code=400, detail="Texte trop long (max 5000 caract√®res).")
    if perspective not in VALID_PERSPECTIVES:
        raise HTTPException(
            status_code=400,
            detail=f"Perspective non valide. Utilisez : {VALID_PERSPECTIVES}"
        )

    # Analyse
    biases = find_biases(text)
    algo_warnings = detect_algorithmic_patterns(text)
    reformulated = apply_inclusive_rewriting(text)
    context_notes = generate_contextual_notes(text) if include_context else []

    # D√©cision d‚Äôinclusivit√©
    is_inclusive = len(biases) == 0 and len(algo_warnings) == 0

    # Note √©ducative
    educational_note = (
        f"Analyse effectu√©e selon une perspective {perspective}. "
        "Pour une transformation profonde, combinez plusieurs angles (f√©ministe, autochtone, √©conomique)."
    )
    if not is_inclusive:
        educational_note += " ‚ö†Ô∏è Ce texte contient des biais structurels √† corriger."

    logger.info(f"Scan termin√© pour : {text[:50]}... | Inclusif : {is_inclusive}")

    return {
        "original_text": text,
        "detected_biases": biases,
        "algorithmic_warnings": algo_warnings,
        "suggested_reformulation": reformulated,
        "added_contextual_notes": context_notes,
        "educational_note": educational_note,
        "is_inclusive": is_inclusive
    }

@app.get("/")
def accueil():
    return {
        "project": "üõ°Ô∏è RE-Educ'-IA ‚Äî Anti-Biais & Inclusion",
        "version": "2.0",
        "mission": "D√©tecter, corriger et pr√©venir les discours racistes, coloniaux et non inclusifs dans les IA et documents.",
        "endpoints": [
            "POST /scan ‚Äî Analyse compl√®te (biais, algorithmes, contexte)",
            "Exemple : {\"text\": \"Les Africains n'avaient pas de civilisation avant la colonisation.\"}"
        ],
        "perspectives": VALID_PERSPECTIVES,
        "documentation": "Acc√©dez √† /docs pour tester l'API interactivement."
    }
